[In Search Of The Engram. Lashley (1950)](https://github.com/dr-darryl-wright/Lashley_1950/)

[In Search Of The Engram. Berlot, Popp and Diedrichsen (2017)](http://www.diedrichsenlab.org/pubs/Berlot_CurrentOpinion_2017.pdf)

[Learning representations by back-propagating errors. Rumelhart, Hinton and Williams (1986)](https://www.nature.com/articles/323533a0.pdf)

Work with Terry Sejnowski on Boltzmann machines:

- [Massively parallel architectures for A.I.: Netl, Thistle, and Boltzmann machines. Fahlman, Hinton and Sejnowski (1983)](http://www.cs.toronto.edu/~hinton/absps/fahlmanBM.pdf)

- [Boltzmann Machines: Constraint satisfaction networks that learn. Hinton, Sejnowski and Ackley (1984)](http://www.cs.toronto.edu/~hinton/absps/bmtr.pdf)

- [A learning algorithm for Boltzmann machines. Ackley, Hinton and Sejnowski (1985)](http://www.cs.toronto.edu/~hinton/absps/cogscibm.pdf)

- [Learning and relearning in Boltzmann machines. Hinton and Sejnowski (1986)](http://www.cs.toronto.edu/~hinton/absps/pdp7.pdf)

- [Separating figure from ground using a Boltzmann machine. Sejnowski and Hinton (1987)](http://www.cs.toronto.edu/~hinton/absps/arbibfigground.pdf)

Yoshua Bengioâ€™s work on embeddings for words in English text:

- [Learning to understand phrases by embedding the dictionary. Hill et al. (2015)](https://arxiv.org/pdf/1504.00548.pdf)

- [A Neural Probabilistic Language Model. Bengio et al. (2003)](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)

[Restricted Boltzmann Machines for Collaborative Filtering. Salakhutdinov, Mnih and Hinton (2007)](http://www.cs.toronto.edu/~fritz/absps/netflix.pdf)

[Phone Recognition using Restricted Boltzmann Machines. Mohamed and Hinton (2010)](http://www.cs.toronto.edu/~hinton/absps/icassp10.pdf)

[Learning to Understand Phrases by Embedding the Dictionary. Hinton, Osindero and Teh (2006)](http://www.cs.toronto.edu/~fritz/absps/ncfast.pdf)

[Variational Learning in Nonlinear Gaussian Belief Networks. Frey and Hinton (1998)](http://www.cs.toronto.edu/~fritz/absps/nlgbn.pdf)

[Keeping Neural Networks Simple by Minimizing the Description Length of the Weights. Hinton and van Camp (1993)](http://www.cs.toronto.edu/~hinton/absps/colt93.pdf)

[Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Srivastava et al. (2014)](http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)

[Rectified Linear Units Improve Restricted Boltzmann Machines. Nair and Hinton (2010)](http://www.cs.toronto.edu/~hinton/absps/reluICML.pdf)

[Learning representations by recirculation. Hinton and McClelland (1988)](http://www.cs.toronto.edu/~hinton/absps/recirculation.pdf)

[Competitive Hebbian learning through spike-timing-dependent synaptic plasticity. Song, Miller and Abbott (2000)](http://www.columbia.edu/cu/neurotheory/Larry/SongNatNeuro00.pdf)

[Using Fast Weights to Attend to the Recent Past. Ba et al. (2016)](https://arxiv.org/pdf/1610.06258.pdf)

[Dynamic Routing between Capsules. Sabour, Frosst and Hinton (2017)](https://arxiv.org/pdf/1710.09829.pdf)
